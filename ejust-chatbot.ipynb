{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8487240,"sourceType":"datasetVersion","datasetId":5063107}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install necessary Requirements\n!pip install langchain==0.1.0\n!pip install python-dotenv==0.19.2\n!pip install streamlit==1.7.1\n!pip install tiktoken==0.3.3\n!pip install faiss-cpu==1.7.1\n!pip install protobuf==3.19.4\n!pip install InstructorEmbedding\n!pip install faiss-gpu\n!pip install -U sentence-transformers==2.2.2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import required libraries\nfrom langchain.llms import GooglePalm\nfrom langchain.chains import RetrievalQA\nfrom langchain.embeddings import HuggingFaceInstructEmbeddings\nfrom langchain.vectorstores import FAISS\nfrom langchain.prompts import PromptTemplate\nfrom langchain.document_loaders.csv_loader import CSVLoader\n\n# Google API key\napi_key = 'AIzaSyDldOj3zW_FdjnnTA-QYxrMLWNXOEvcRW8'\n\n# Initialize the GooglePalm language model with the API key\nllm = GooglePalm(google_api_key=api_key, temperature=0.1)\n\n# Load data from the CSV file\nloader = CSVLoader(file_path='/kaggle/input/ejust-admission-data/all_data.csv', source_column=\"Question\")\ndata = loader.load()\n\n# Initialize HuggingFace instructor embeddings\ninstructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\")\n\n# Create a FAISS instance for vector database from 'data'\nvectordb = FAISS.from_documents(documents=data, embedding=instructor_embeddings)\n\n# Create a retriever for querying the vector database\nretriever = vectordb.as_retriever(score_threshold=0.1)\n\n# Define a prompt template for generating answers\nprompt_template = \"\"\"Given the following context and a question, generate an answer based on this context only.\nIn the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\nIf the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n\nCONTEXT: {context}\n\nQUESTION: {question}\"\"\"\n\n# Initialize the PromptTemplate with the defined template\nPROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n\n# Define additional keyword arguments for the chain\nchain_type_kwargs = {\"prompt\": PROMPT}\n\n# Initialize the RetrievalQA chain\nchain = RetrievalQA.from_chain_type(llm=llm,\n                                    chain_type=\"stuff\",\n                                    retriever=retriever,\n                                    input_key=\"query\",\n                                    return_source_documents=True,\n                                    chain_type_kwargs=chain_type_kwargs)\n\n# Example query to the chain\nresponse = chain(\"what are the admission fees?\")\n\n# Extracting and printing the response in the desired format\nformatted_response = f\"question: '{response['query']}'\\nresponse: '{response['result']}'\"\nprint(formatted_response)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:54:59.473036Z","iopub.execute_input":"2024-05-22T14:54:59.474687Z","iopub.status.idle":"2024-05-22T14:57:55.881513Z","shell.execute_reply.started":"2024-05-22T14:54:59.474626Z","shell.execute_reply":"2024-05-22T14:57:55.880146Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"load INSTRUCTOR_Transformer\nmax_seq_length  512\nquestion: 'what are the admission fees?'\nresponse: 'The amount of the Application Fees is 1000 EGP.'\n","output_type":"stream"}]},{"cell_type":"code","source":"# Example query to the chain\nresponse = chain(\"What faculties do ejust have?\")\n\n# Extracting and printing the response in the desired format\nformatted_response = f\"question: '{response['query']}'\\nresponse: '{response['result']}'\"\nprint(formatted_response)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T15:05:10.638259Z","iopub.execute_input":"2024-05-22T15:05:10.638763Z","iopub.status.idle":"2024-05-22T15:05:12.014141Z","shell.execute_reply.started":"2024-05-22T15:05:10.638728Z","shell.execute_reply":"2024-05-22T15:05:12.013133Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"question: 'What faculties do ejust have?'\nresponse: 'Response: E-JUST has four faculties: Faculty of Engineering, Faculty of Science, Faculty of Business Administration, and Faculty of Humanities and Social Sciences.'\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}